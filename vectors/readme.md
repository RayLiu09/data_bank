## 矢量化处理
- 读取文档

    目前采用PyPdf2读取pdf文件，使用Unstructured库读取其他类型的文档
- 文档分割Chunking
    
    包含三种分割方式：基于语句的分割SentenceChunking，基于单词的分割WordChunking和基于Token的TokenChunking。其中基于语句和单词的分割
    使用开源文本分析库spaCy，不依赖任何预训练统计模型，语句分割采用基于规则的Sentencizer
- 向量化Embedding

    目前支持向量化方式：
- 索引Indexing
    
    
## 存在不足
- 读取文档部分，只能全局获取文档内容，无法精确分析内容类型，比如哪些是表格，哪些是图片，哪些是描述性内容，哪些是Header，哪些是Footer，
以至于无法进一步进行数据清洗
- 文档分割部分，不管是基于语句的分割，基于单词的分割还是基于固定token的分割都无法感知文本的上下文语义，容易导致上下文丢失；暂无解决思路


 扩展
- Weaviate矢量数据库开启""多租户"特性，支持不同业务部门数据隔离； 